{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to team Klima KÃ¤mpfer's notebook for the WiDS datathon 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What data are we exploring here? \n",
    "\n",
    "### The data in this notebook looks at energy efficiency of buildings in the United States. The goal is to find the best predictors of energy efficienct, that is those predictors that are most correlated with the outcome variable and give us the strongest model in terms of predicting the outcome variable. The dataset can be downloaded [here](https://www.kaggle.com/c/widsdatathon2022/data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data cleaning and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning train set (steps need to be repeated for test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set rows: 75757\n",
      "Train set columns: 64\n"
     ]
    }
   ],
   "source": [
    "#check how many rows and colums we have\n",
    "print('Train set rows:',train.shape[0])\n",
    "print('Train set columns:',train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object/string type variables need to be encoded to integer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Assigning numerical values and storing in orig column\n",
    "train['building_class'] = labelencoder.fit_transform(train['building_class'])\n",
    "train['facility_type'] = labelencoder.fit_transform(train['facility_type'])\n",
    "train['State_Factor'] = labelencoder.fit_transform(train['State_Factor'])\n",
    "\n",
    "test['building_class'] = labelencoder.fit_transform(test['building_class'])\n",
    "test['facility_type'] = labelencoder.fit_transform(test['facility_type'])\n",
    "test['State_Factor'] = labelencoder.fit_transform(test['State_Factor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use simple imputer for numerical columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "null_cols=['year_built', 'energy_star_rating', 'direction_max_wind_speed', 'direction_peak_wind_speed', 'max_wind_speed',\n",
    "          'days_with_fog']\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "train[null_cols]  = imp.fit_transform(train[null_cols])\n",
    "test[null_cols]  = imp.transform(test[null_cols])\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_Factor                2.000000\n",
      "State_Factor               1.000000\n",
      "building_class             1.000000\n",
      "facility_type              5.000000\n",
      "floor_area            117161.500000\n",
      "year_built                45.000000\n",
      "energy_star_rating        11.000000\n",
      "ELEVATION                 33.600000\n",
      "january_min_temp           9.000000\n",
      "january_avg_temp           8.725806\n",
      "january_max_temp           6.000000\n",
      "february_min_temp         17.000000\n",
      "february_avg_temp         10.620690\n",
      "february_max_temp          9.000000\n",
      "march_min_temp            15.000000\n",
      "march_avg_temp            12.983871\n",
      "march_max_temp            16.000000\n",
      "april_min_temp             7.000000\n",
      "april_avg_temp             2.433333\n",
      "april_max_temp             8.000000\n",
      "may_min_temp               7.000000\n",
      "may_avg_temp               2.306452\n",
      "may_max_temp               3.000000\n",
      "june_min_temp              5.000000\n",
      "june_avg_temp              1.666667\n",
      "june_max_temp              4.000000\n",
      "july_min_temp              3.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#detect outliers, outliers are one of the primary reasons for resulting in a less accurate model\n",
    "#it's a good idea to remove them\n",
    "\n",
    "Q1 = train.iloc[0:49048,0:27].quantile(0.25) # first quartile (25%)\n",
    "Q3 = train.iloc[0:49048,0:27].quantile(0.75) # third quartile (75%)\n",
    "IQR = Q3 - Q1 # Interquartile range (IQR)\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set rows: 75757\n",
      "Train set columns: 64\n"
     ]
    }
   ],
   "source": [
    "# Checking Train set size before removing outliers\n",
    "print('Train set rows:',train.shape[0])\n",
    "print('Train set columns:',train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train[~((train < (Q1 - 1.5 * IQR)) |(train > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set rows: 75757\n",
      "Train set columns: 64\n"
     ]
    }
   ],
   "source": [
    "# Checking Train set size after removing outliers\n",
    "print('Train set rows:',train.shape[0])\n",
    "print('Train set columns:',train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set: Object/string type variables need to be encoded to integer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test features\n",
    "X = train[['energy_star_rating', 'january_min_temp', 'january_avg_temp', 'february_avg_temp', 'february_min_temp', \n",
    "'march_avg_temp', 'march_min_temp', 'april_avg_temp','april_min_temp', 'february_max_temp', 'november_min_temp', \n",
    "'july_min_temp','september_avg_temp', 'snowdepth_inches', 'precipitation_inches','august_avg_temp', 'days_below_20F',\n",
    "'june_avg_temp','cooling_degree_days','july_avg_temp','days_below_30F','heating_degree_days','snowfall_inches',\n",
    "'facility_type','floor_area','year_built', 'State_Factor', 'days_with_fog', 'direction_max_wind_speed']] \n",
    "y = train['site_eui']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train features\n",
    "\n",
    "test_features = test[['energy_star_rating', 'january_min_temp', 'january_avg_temp', 'february_avg_temp', 'february_min_temp', \n",
    "'march_avg_temp', 'march_min_temp', 'april_avg_temp','april_min_temp', 'february_max_temp', 'november_min_temp', \n",
    "'july_min_temp','september_avg_temp', 'snowdepth_inches', 'precipitation_inches','august_avg_temp', 'days_below_20F',\n",
    "'june_avg_temp','cooling_degree_days','july_avg_temp','days_below_30F','heating_degree_days','snowfall_inches','facility_type',\n",
    "'floor_area','year_built', 'State_Factor','days_with_fog','direction_max_wind_speed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Deep NN Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "      normalizer,\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(64, activation='elu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2883.6458 - root_mean_squared_error: 53.6996 - val_loss: 4573.6777 - val_root_mean_squared_error: 67.6290\n",
      "Epoch 2/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2588.5718 - root_mean_squared_error: 50.8780 - val_loss: 4029.4692 - val_root_mean_squared_error: 63.4781\n",
      "Epoch 3/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2558.0198 - root_mean_squared_error: 50.5769 - val_loss: 4330.8594 - val_root_mean_squared_error: 65.8093\n",
      "Epoch 4/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2526.1838 - root_mean_squared_error: 50.2612 - val_loss: 4665.7207 - val_root_mean_squared_error: 68.3061\n",
      "Epoch 5/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2501.1782 - root_mean_squared_error: 50.0118 - val_loss: 4655.3877 - val_root_mean_squared_error: 68.2304\n",
      "Epoch 6/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2480.2441 - root_mean_squared_error: 49.8020 - val_loss: 4706.9287 - val_root_mean_squared_error: 68.6071\n",
      "Epoch 7/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2449.5061 - root_mean_squared_error: 49.4925 - val_loss: 5249.5015 - val_root_mean_squared_error: 72.4534\n",
      "Epoch 8/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2425.5425 - root_mean_squared_error: 49.2498 - val_loss: 4204.9800 - val_root_mean_squared_error: 64.8458\n",
      "Epoch 9/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2386.4368 - root_mean_squared_error: 48.8512 - val_loss: 4860.0996 - val_root_mean_squared_error: 69.7144\n",
      "Epoch 10/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2345.3208 - root_mean_squared_error: 48.4285 - val_loss: 5838.2925 - val_root_mean_squared_error: 76.4087\n",
      "Epoch 11/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2297.6965 - root_mean_squared_error: 47.9343 - val_loss: 5310.1685 - val_root_mean_squared_error: 72.8709\n",
      "Epoch 12/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2253.1958 - root_mean_squared_error: 47.4678 - val_loss: 6249.6411 - val_root_mean_squared_error: 79.0547\n",
      "Epoch 13/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2206.5693 - root_mean_squared_error: 46.9741 - val_loss: 4723.0156 - val_root_mean_squared_error: 68.7242\n",
      "Epoch 14/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2176.5793 - root_mean_squared_error: 46.6538 - val_loss: 5990.0967 - val_root_mean_squared_error: 77.3957\n",
      "Epoch 15/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2151.8455 - root_mean_squared_error: 46.3880 - val_loss: 5714.8882 - val_root_mean_squared_error: 75.5969\n",
      "Epoch 16/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2138.1252 - root_mean_squared_error: 46.2399 - val_loss: 4490.8315 - val_root_mean_squared_error: 67.0137\n",
      "Epoch 17/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2116.2842 - root_mean_squared_error: 46.0031 - val_loss: 4022.7922 - val_root_mean_squared_error: 63.4255\n",
      "Epoch 18/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2101.5288 - root_mean_squared_error: 45.8424 - val_loss: 4883.1738 - val_root_mean_squared_error: 69.8797\n",
      "Epoch 19/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2082.7566 - root_mean_squared_error: 45.6372 - val_loss: 3741.0654 - val_root_mean_squared_error: 61.1642\n",
      "Epoch 20/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2071.9216 - root_mean_squared_error: 45.5184 - val_loss: 5915.3242 - val_root_mean_squared_error: 76.9111\n",
      "Epoch 21/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2070.1782 - root_mean_squared_error: 45.4992 - val_loss: 5219.1733 - val_root_mean_squared_error: 72.2438\n",
      "Epoch 22/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2061.5771 - root_mean_squared_error: 45.4046 - val_loss: 4702.3247 - val_root_mean_squared_error: 68.5735\n",
      "Epoch 23/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2045.4236 - root_mean_squared_error: 45.2264 - val_loss: 3469.3596 - val_root_mean_squared_error: 58.9013\n",
      "Epoch 24/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2038.8997 - root_mean_squared_error: 45.1542 - val_loss: 4617.1748 - val_root_mean_squared_error: 67.9498\n",
      "Epoch 25/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2039.1808 - root_mean_squared_error: 45.1573 - val_loss: 4760.7451 - val_root_mean_squared_error: 68.9982\n",
      "Epoch 26/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2032.9961 - root_mean_squared_error: 45.0888 - val_loss: 6484.1436 - val_root_mean_squared_error: 80.5242\n",
      "Epoch 27/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2028.2887 - root_mean_squared_error: 45.0365 - val_loss: 3594.8240 - val_root_mean_squared_error: 59.9569\n",
      "Epoch 28/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2010.9238 - root_mean_squared_error: 44.8433 - val_loss: 7342.6187 - val_root_mean_squared_error: 85.6891\n",
      "Epoch 29/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2007.0939 - root_mean_squared_error: 44.8006 - val_loss: 5667.7676 - val_root_mean_squared_error: 75.2846\n",
      "Epoch 30/30\n",
      "1658/1658 [==============================] - 2s 1ms/step - loss: 2009.9716 - root_mean_squared_error: 44.8327 - val_loss: 4548.4790 - val_root_mean_squared_error: 67.4424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe162c05e20>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, validation_split=0.3, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up model for test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set rows: 9705\n",
      "Test set columns: 63\n"
     ]
    }
   ],
   "source": [
    "#Checking size of the test set\n",
    "print('Test set rows:',test.shape[0])\n",
    "print('Test set columns:',test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_official = model.predict(test_features) # Getting predicted values for submission\n",
    "y_hat_official = y_hat_official.flatten() # Flattening the output tensor to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_predicted = pd.DataFrame({'site_eui': y_hat_official}) # Creating a dataframe of predicted values\n",
    "id_predicted = pd.DataFrame({'id': test['id']}) # Creating a dataframe of test ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file_df = pd.concat([id_predicted, submission_predicted], axis=1) # Combining the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file shape: (9705, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>site_eui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75757</td>\n",
       "      <td>235.962006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75758</td>\n",
       "      <td>198.178589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75759</td>\n",
       "      <td>278.712067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75760</td>\n",
       "      <td>245.982117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75761</td>\n",
       "      <td>238.155182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    site_eui\n",
       "0  75757  235.962006\n",
       "1  75758  198.178589\n",
       "2  75759  278.712067\n",
       "3  75760  245.982117\n",
       "4  75761  238.155182"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Submission file shape:\", submission_file_df.shape)\n",
    "submission_file_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file_df.to_csv('submission_file_tf_v9.csv', index=False) # Saving the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
